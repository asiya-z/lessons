{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled28.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "tbbjIWP8FEYi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Нелинейные границы при добавлении признаков\n",
        "\n",
        "При обучении бинарного классификатора мы использовали следующее выражение для определения \"уверенности\" предсказания:\n",
        "$$\\vec{\\omega}\\cdot\\vec{x}$$\n",
        "\n",
        "Рассмотрим случай,  когда каждый обект описывался  двумя переменными: $\\vec{x}=(x_1, x_2)$. Для удобства обозначим их $x$ и $y$. Тогда выражение для уверенности классивфикатора можно записать следующим образом (не учитываем свободный член для краткости):\n",
        "$$\\vec{\\omega}\\cdot\\vec{x}=\\omega_1\\cdot x+\\omega_2\\cdot y$$\n",
        "\n",
        "Если это выражение оказывалось положительным, то мы считали что объект принадлежит к классу \"I\", если отрицателным, то к классу \"II\". \n",
        "\n",
        "Границей между классами является множество точек для которого выполняется соотношение:\n",
        "$$\\omega_1\\cdot x+\\omega_2\\cdot y=0$$\n",
        "\n",
        "Это уравнение задает прямую, то есть линейную границу.\n",
        "\n",
        "Как получить в качестве границы какую-то кривую? Надо изменить уравнение границы.\n",
        "\n",
        "Для этого мы можем добавить новые признаки к описанию каждого объекта. Откуда их взять? Сгенерировать из старых, например\n",
        "\n",
        "$$x_3 = x^2$$\n",
        "\n",
        "Тогда вектор описания каждого объекта будет иметь следующий вид:\n",
        "$$\\vec{x}=(x_1, \\;x_2)=(x,\\; y)\\;\\; \\rightarrow\\;\\; \\vec{x}'=(x_1,\\; x_2,\\;x_3)=(x,\\;y,\\;x^2)$$\n",
        "\n",
        "Теперь вектор $\\vec{\\omega}'$ тоже будет содержать 3 компоненты и уверенность нашего классификатора будет описываться следующим выражением:\n",
        "\n",
        "$$\\vec{\\omega}'\\cdot\\vec{x}'=\\omega_1\\cdot x+\\omega_2\\cdot y+\\omega_3\\cdot x^2$$\n",
        "\n",
        "А уравнение границы будет иметь следующи вид:\n",
        "$$\\omega_1\\cdot x+\\omega_2\\cdot y+\\omega_3\\cdot x^2=0$$\n",
        "\n",
        "Переносим $y$ в другую часть, делим на $\\omega_2$ и получаем в привычном виде уравнение параболы.\n",
        "\n",
        "Теперь если при обучении мы получим, что $\\omega_3$ оказалось близко к 0, значит граница останется линейной, то есть модель получила дополнительные возможности, но не потеряла старые.\n",
        "\n",
        "Заметим, что хотя теперь каждый объекты описывается тремя параметрами, но они зависят друг от друга, и  граница все еще будет лежать в  плоскости.\n",
        "\n",
        "В случае более сложных границ мы можем еще больше расширить \"емкость\" нашей модели добавляя дополнительные слагаемые, например:\n",
        "$$x_4=y^2$$\n",
        "$$x_5=x\\cdot y$$\n",
        "$$x_6=x^2\\cdot y$$\n",
        "$$\\ldots$$\n",
        "\n",
        "Чем больше параметров, тем более разнообразным разделительным поверхностям можно обучить модель. \n",
        "Почему тогда сразу не добавить как можно больше различных слагаемых?\n",
        "\n",
        "1. Упадет скорость обучения\n",
        "2. Модель может переобучится и показывать плохие результаты на новых данных\n",
        "\n",
        "Обычно в качестве параметра при добавлении новых признаков используют максимальное количество множителей в слагаемом: $x_3$,  $x_4$ и  $x_5$ содержат по 2 множителя,  а  $x_6$ уже три.\n",
        "\n",
        "Значит мы можем варьируя этот параметр обучить несколько моделей и выбрать из них лучшую.\n",
        "\n",
        "\n",
        "# Метрики качества\n",
        "\n",
        "Как сравнивать разные модели? \n",
        "Для обучения моделелей мы вводили функцию потерь, которая показывала насколько предсказания модели были близки к известным. Однако рассмотрени только функции потерь не всегда достаточно.\n",
        "\n",
        "Рассмотрим пример бинарной классификации. Введем обозначения традиционные называния для классов: Positive и Negative. Тогда все предсказания мы можем разделить на 4 типа:\n",
        "1. True Positive (TP) - правильно предсказанные объекты из Positive класса.\n",
        "1. False Positive (FP) - объекты из Negative класса, которые модель ошибочно отнесла к Positive классу\n",
        "1. True Negative (TN) - правильно предсказанные объекты из Negative класса.\n",
        "1. False Negative (FN) - объекты из Positive класса, которые модель ошибочно отнесла к Negative классу\n",
        "\n",
        "Интуитивным параметром описывающим качество предсказаний можно считать точность:\n",
        "$$accuracy=\\frac{TP+TN}{TP+FP+TN+FN}$$\n",
        "те доля правильных ответов, среди всех.\n",
        "\n",
        "Стоит ли доверять предсказаниям модели с точностью, например более 97%?\n",
        "\n",
        "Пусть мы хотим узнать вероятность сильного урагана, которых за год бывает ровно 10.\n",
        "Тогда если наши модель выдаст для всех дней ответ Negativ, то точность будет:\n",
        "$$accuracy=\\frac{355}{365}\\approx 0.972$$\n",
        "Очень высокая точность, но про ураганы мы не узнали абсолютно ничего нового) То есть для нас эта модель бесполезна.\n",
        "\n",
        "Нужны другие критерии.\n",
        "1. Presicion:\n",
        "$$presicion = \\frac{}{}\n",
        "\n",
        "\n",
        "## \n",
        "\n",
        "\n",
        "# Кривые Обучения"
      ]
    },
    {
      "metadata": {
        "id": "fUmHKj98FDNL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}