{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled28.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "tbbjIWP8FEYi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Нелинейные границы при добавлении признаков\n",
        "\n",
        "При обучении бинарного классификатора мы использовали следующее выражение для определения \"уверенности\" предсказания:\n",
        "$$\\vec{\\omega}\\cdot\\vec{x}$$\n",
        "\n",
        "Рассмотрим случай,  когда каждый обект описывался  двумя переменными: $\\vec{x}=(x_1, x_2)$. Для удобства обозначим их $x$ и $y$. Тогда выражение для уверенности классивфикатора можно записать следующим образом (не учитываем свободный член для краткости):\n",
        "$$\\vec{\\omega}\\cdot\\vec{x}=\\omega_1\\cdot x+\\omega_2\\cdot y$$\n",
        "\n",
        "Если это выражение оказывалось положительным, то мы считали что объект принадлежит к классу \"I\", если отрицателным, то к классу \"II\". \n",
        "\n",
        "Границей между классами является множество точек для которого выполняется соотношение:\n",
        "$$\\omega_1\\cdot x+\\omega_2\\cdot y=0$$\n",
        "\n",
        "Это уравнение задает прямую, то есть линейную границу.\n",
        "\n",
        "Как получить в качестве границы какую-то кривую? Надо изменить уравнение границы.\n",
        "\n",
        "Для этого мы можем добавить новые признаки к описанию каждого объекта. Откуда их взять? Сгенерировать из старых, например\n",
        "\n",
        "$$x_3 = x^2$$\n",
        "\n",
        "Тогда вектор описания каждого объекта будет иметь следующий вид:\n",
        "$$\\vec{x}=(x_1, \\;x_2)=(x,\\; y)\\;\\; \\rightarrow\\;\\; \\vec{x}'=(x_1,\\; x_2,\\;x_3)=(x,\\;y,\\;x^2)$$\n",
        "\n",
        "Теперь вектор $\\vec{\\omega}'$ тоже будет содержать 3 компоненты и уверенность нашего классификатора будет описываться следующим выражением:\n",
        "\n",
        "$$\\vec{\\omega}'\\cdot\\vec{x}'=\\omega_1\\cdot x+\\omega_2\\cdot y+\\omega_3\\cdot x^2$$\n",
        "\n",
        "А уравнение границы будет иметь следующи вид:\n",
        "$$\\omega_1\\cdot x+\\omega_2\\cdot y+\\omega_3\\cdot x^2=0$$\n",
        "\n",
        "Переносим $y$ в другую часть, делим на $\\omega_2$ и получаем в привычном виде уравнение параболы.\n",
        "\n",
        "Теперь если при обучении мы получим, что $\\omega_3$ оказалось близко к 0, значит граница останется линейной, то есть модель получила дополнительные возможности, но не потеряла старые.\n",
        "\n",
        "Заметим, что хотя теперь каждый объекты описывается тремя параметрами, но они зависят друг от друга, и  граница все еще будет лежать в  плоскости.\n",
        "\n",
        "В случае более сложных границ мы можем еще больше расширить \"емкость\" нашей модели добавляя дополнительные слагаемые, например:\n",
        "$$x_4=y^2$$\n",
        "$$x_5=x\\cdot y$$\n",
        "$$x_6=x^2\\cdot y$$\n",
        "$$\\ldots$$\n",
        "\n",
        "Чем больше параметров, тем более разнообразным разделительным поверхностям можно обучить модель. \n",
        "Почему тогда сразу не добавить как можно больше различных слагаемых?\n",
        "\n",
        "1. Упадет скорость обучения\n",
        "2. Модель может переобучится и показывать плохие результаты на новых данных\n",
        "\n",
        "Обычно в качестве параметра при добавлении новых признаков используют максимальное количество множителей в слагаемом: $x_3$,  $x_4$ и  $x_5$ содержат по 2 множителя,  а  $x_6$ уже три.\n",
        "\n",
        "Значит мы можем варьируя этот параметр обучить несколько моделей и выбрать из них лучшую.\n",
        "\n",
        "\n",
        "# Метрики качества\n",
        "\n",
        "Как сравнивать разные модели? \n",
        "Для обучения моделелей мы вводили функцию потерь, которая показывала насколько предсказания модели были близки к известным. Однако рассмотрени только функции потерь не всегда достаточно.\n",
        "\n",
        "Рассмотрим пример бинарной классификации. Введем обозначения традиционные называния для классов: Positive и Negative. Тогда все предсказания мы можем разделить на 4 типа:\n",
        "1. True Positive (TP) - правильно предсказанные объекты из Positive класса.\n",
        "1. False Positive (FP) - объекты из Negative класса, которые модель ошибочно отнесла к Positive классу\n",
        "1. True Negative (TN) - правильно предсказанные объекты из Negative класса.\n",
        "1. False Negative (FN) - объекты из Positive класса, которые модель ошибочно отнесла к Negative классу\n",
        "\n",
        "![Confusion matrix](https://raw.githubusercontent.com/mlforschool/lessons/master/5_Logistic_Regression/images/Matrix.PNG)\n",
        "![Типы предсказаний](https://raw.githubusercontent.com/mlforschool/lessons/master/5_Logistic_Regression/images/PredictionTypes.png)\n",
        "\n",
        "Интуитивным параметром описывающим качество предсказаний можно считать долю правильных ответов, среди всех:\n",
        "$$accuracy=\\frac{TP+TN}{TP+FP+TN+FN}$$\n",
        "\n",
        "Стоит ли доверять предсказаниям модели с долей правильных ответов, например, более 97%?\n",
        "\n",
        "Рассмотрим случай дисбаланса классов  -  значительное отличие представителей разных классов.\n",
        "\n",
        "Пусть мы хотим узнать вероятность сильного урагана, которых за год бывает ровно 10.\n",
        "Тогда если наши модель выдаст для всех дней ответ Negativ, то точность будет:\n",
        "$$accuracy=\\frac{355}{365}\\approx 0.972$$\n",
        "Очень высокая точность, но про ураганы мы не узнали абсолютно ничего нового) То есть для нас эта модель бесполезна.\n",
        "\n",
        "Нужны другие критерии.\n",
        "1. Точность (Presicion):\n",
        "$$presicion = \\frac{TP}{TP+FP}$$\n",
        " показывает, какая доля объектов, выделенных классификатором как поло-\n",
        "жительные, действительно является положительными. \n",
        "\n",
        "2. Полнота (Recall):\n",
        "$$recall = \\frac{TP}{TP+FN}$$\n",
        "показывает, какая\n",
        "часть положительных объектов была выделена классификатором.\n",
        "\n",
        "В нашем случае:\n",
        "$$presicion = \\frac{TP}{TP+FP}=\\frac{0}{0+0} - не определена$$\n",
        "$$recall = \\frac{TP}{TP+FN}  = \\frac{0}{0+10}=0$$\n",
        "\n",
        "Лучшие значения для каждой из метрик - 1.\n",
        "\n",
        "Для одновременного учета метрик вводят величину $F_1$:\n",
        "\n",
        "$$F_1 = 2\\cdot\\frac{presicion\\cdot recall}{presicion+recall}$$\n",
        " \n",
        "\n",
        "##Пример из лекций [Евгения Соколова](https://github.com/esokolov/ml-course-msu/blob/master/ML15/lecture-notes/Sem05_metrics.pdf)\n",
        "\n",
        "Рассмотрим задачу бинарной классификации с миллионом объектов (N = 1.000.000), где доля объектов первого класса составляет 1% (P = 10.000). Мы знаем, что доля правильных ответов будет вести себя не вполне интуитивно на данной несбалансированной выборке, и поэтому выберем точность и полноту для измерения качества классификаторов. Поскольку мы хотим решить задачу хорошо, то введём требования, что и точность, и полнота должны быть не менее 90%. Эти требо-\n",
        "вания кажутся вполне разумными, если забыть о соотношении классов. Попробуем теперь оценить, какая доля правильных ответов должна быть у классификатора, удовлетворяющего нашим требованиям.\n",
        "\n",
        "Всего в выборке 10.000 положительных объектов, и для достижения полноты 90% мы должны отнести как минимум 9.000 к положительному классу. Получаем TP = 9000, FN = 1000. Так как точность тоже должна быть не меньше 90%, получаем FP = 1000. Отсюда получаем, что доля правильных ответов должна быть равна 2.000/1.000.000 = 99.8%! Это крайне высокий показатель, и его редко удаётся достичь на таких выборках во многих предметных областях.\n",
        "\n",
        "Существуют и другие метрики. Одна из часто используемых - ROC AUC. В ее основе лежит идея, что мы имее предсказания вероятностей для классов, и далее можем менять порог. Например можем отнести к классу \"I\" все объекты для которых вероятность больше чем 0.75. Рассматривая  значения порога как переменную можно получить зависимость того насколько хороша наша модель, от порога. Площадь под этим графиком и будет итоговой характеристикой: чем ближе к 1 тем лучше. "
      ]
    },
    {
      "metadata": {
        "id": "fUmHKj98FDNL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}