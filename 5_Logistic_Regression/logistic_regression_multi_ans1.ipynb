{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled26.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "l72IuzKlTGcQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Классификация\n",
        "\n",
        "В прошлый раз мы рассмотрели предсказание вероятностей для 2 классов.\n",
        "\n",
        "Что делать в случае нескольких классов?\n",
        "\n",
        "###Использовать несколько ,бинарных классификаторов\n",
        "\n",
        "    Для каждого класса обучим классификатор, который делит объекты на заданный класс и все остальные. Напрмер для первого классификатора разделим вск объекты на 2 класса: первый и все остальные. Далее обучим его как в прошлый раз. Аналогично обучим остальные классификаторы для других классов.\n",
        "    Для предсказания класса нового объекта будем искать максимум из предсказанных вероятностей среди всех классификаторов. \n",
        "    \n",
        "    \n",
        "###Cпециальную функцию, которя называется softmax.\n",
        "\n",
        "Пусть  у нас 3 класса, нам надо предсказать вероятности для каждого из них.  Вероятности должны лежатьв диапазоне [0, 1] и их сумма должна быть равна 1.\n",
        "\n",
        "Введем набор весов для каждого класса: для класса 1 введем ветор $\\vec{\\omega_1}$, для класса 2 - $\\vec{\\omega_2}$ и $\\vec{\\omega_3}$ для класса 3. Эти 3 вектора можно обединить в матрицу параметров:\n",
        "$$W=(\\vec{\\omega_1},\\;\\vec{\\omega_2},\\;\\vec{\\omega_3})$$\n",
        "\n",
        "\n",
        "Мы можем посчитать для каждого примера три выражения: $\\vec{x}\\cdot\\vec{\\omega_1}$, $\\vec{x}\\cdot\\vec{\\omega_2}$ и Тогда мы можем посчитать для каждого примера три выражения: $\\vec{x}\\cdot\\vec{\\omega_1}$,  $\\vec{x}\\cdot\\vec{\\omega_2}$ и $\\vec{x}\\cdot\\vec{\\omega_3}$.\n",
        "\n",
        "В матричной форме:\n",
        "$$margin = W\\cdot\\vec{x}$$\n",
        "Получим вектор из 3 компонент.\n",
        "\n",
        "Однако эти выражения могут принимать значения в диапазоне $(-\\infty, \\infty)$. Преобразуем их в верояности:\n",
        "$$p_1=\\frac{e^{\\vec{x}\\cdot\\vec{\\omega_1}}}{e^{\\vec{x}\\cdot\\vec{\\omega_1}}+e^{\\vec{x}\\cdot\\vec{\\omega_2}}+e^{\\vec{x}\\cdot\\vec{\\omega_3}}}$$\n",
        "$$p_2=\\frac{e^{\\vec{x}\\cdot\\vec{\\omega_2}}}{e^{\\vec{x}\\cdot\\vec{\\omega_1}}+e^{\\vec{x}\\cdot\\vec{\\omega_2}}+e^{\\vec{x}\\cdot\\vec{\\omega_3}}}$$\n",
        "$$p_3=\\frac{e^{\\vec{x}\\cdot\\vec{\\omega_3}}}{e^{\\vec{x}\\cdot\\vec{\\omega_1}}+e^{\\vec{x}\\cdot\\vec{\\omega_2}}+e^{\\vec{x}\\cdot\\vec{\\omega_3}}}$$\n",
        "\n",
        "Можно убедиться, что такие выражения положительны и в сумме дают 1.\n",
        "Эти три вероятности обединяют в вектор $\\vec{p}$:\n",
        "$$\\vec{p}=(p_1,\\;p_2,\\;p_3)$$\n",
        "\n",
        "\n",
        "\n",
        "Для обучения модели представим метки классов в виде векторов, для первого класса:\n",
        "$$\\vec{y_1}=(1,\\;0,\\;0)$$\n",
        "$$\\vec{y_2}=(0,\\;1,\\;0)$$\n",
        "$$\\vec{y_3}=(0,\\;0,\\;1)$$\n",
        "\n",
        "\n",
        "В качестве функции потерь мы можем использовать стандартную среднюю разность квадратов. Для каждого примера мы знаем корректный класс, преобразуем его в соответствующий вектор и обозначи $\\vec{y_i}$. Тогда можем посчитать отклонение каждой компоненты:\n",
        "$$L=\\frac{1}{N}\\sum_i ((p_{i1}-y_{i1})^2+(p_{i2}-y_{i2})^2+(p_{i3}-y_{i3})^2)$$\n",
        "\n",
        "На практике используют другую функцию потерь, которая дает лучшие результаты при обучении: «логлосс» (logloss / log_loss), перекрёстной / кросс-энтропией (Cross Entropy).\n",
        "\n",
        "Для одного объекта:\n",
        "$$L_i  = \\sum_j -y_ij\\cdot log(p_{ij})$$\n",
        "В случае трех классов:\n",
        "$$L_i  = -y_{i1}\\cdot log(p_{i1})-y_{i2}\\cdot log(p_{i2})-y_{i3}\\cdot log(p_{i3})$$\n",
        "Полная функция потерь:\n",
        "$$L=\\frac{1}{N}\\sum_i L_i$$"
      ]
    },
    {
      "metadata": {
        "id": "20a6VHgiya9Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "p13 - вероятность того, что 1ый обект принадлежит классу 3\n",
        "p52 - вероятность того, что 5ый обект принадлежит классу 2\n",
        "\n",
        "p_i3 - вероятность того, что i-ый обект принадлежит классу 3\n",
        "\n",
        "p_i2 - вероятность того, что i-ый обект принадлежит классу 2\n",
        "\n",
        "p_i1 - вероятность того, что i-ый обект принадлежит классу 1\n",
        "\n",
        "p_ij - вероятность того, что i-ый обект принадлежит классу j \n"
      ]
    },
    {
      "metadata": {
        "id": "9NJS27CoTEux",
        "colab_type": "code",
        "outputId": "163c826e-5561-49d2-e61b-fac68d8ed186",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# посчитать кросс энтропию для заданных данных и весов\n",
        "import numpy as np\n",
        "\n",
        "n = 20\n",
        "\n",
        "# генерируем данные\n",
        "max_range = 10\n",
        "X = (np.random.random( (n,4) )-0.5) * max_range \n",
        "y = np.random.randint(0,3,(n))\n",
        "\n",
        "# генерируем данные\n",
        "W = np.random.random((4,3))\n",
        "\n",
        "scalar = np.dot(X, W)\n",
        "print(\"Скалярные произведения: \", scalar.shape)\n",
        "\n",
        "exps = np.exp(scalar)\n",
        "print(\"Экспоненты от скалярных произведений: \", exps.shape)\n",
        "\n",
        "# суммируем вдоль оси \"1\", то есть по столбцам \n",
        "sums_of_exp = np.sum(exps, axis=1)\n",
        "print(\"Знаменатели: \", sums_of_exp.shape)\n",
        "\n",
        "# вычисляем вероятности\n",
        "# создаем массив зваполненный нулями\n",
        "probabilities0 = np.zeros((n,3))\n",
        "probabilities1 = np.zeros((n,3))\n",
        "probabilities2 = np.zeros((n,3))\n",
        "\n",
        "# не оптимальный вариант\n",
        "# перебираем строчки, корторые содержат экспоненты\n",
        "# for i in range(len(sums)):\n",
        "#   перебераем все элементы в строке\n",
        "#   for j in range(len(probabilities1[i])):\n",
        "#        probabilities0[i][j] = exps[i][j] / sums_of_exp[i]\n",
        "\n",
        "# Более оптимальный вариант:\n",
        "# перебираем строчки, корторые содержат экспоненты\n",
        "for i in range(len(sums_of_exp)):\n",
        "    # делим i-ую строчку с экспонентами, на i-ую сумму и записываем результат в i-ую строку вероятностей\n",
        "    probabilities1[i] = exps[i] / sums_of_exp[i]\n",
        "    \n",
        "# Самый оптимальный вариант с broadcating\n",
        "probabilities2 = exps / sums_of_exp.reshape(-1, 1)\n",
        "\n",
        "# проверки, можно раскомментировать\n",
        "# суммируем вероятности того, что объект принадлежит какому-то из классов. Должны получить 1 для каждого объекта\n",
        "# print(np.sum(probabilities1, axis=1))\n",
        "# print(np.sum(probabilities2, axis=1))\n",
        "\n",
        "# при совпадении должны быть все нули\n",
        "# print(probabilities1 - probabilities2)\n",
        "\n",
        "\n",
        "# создаем для каждого обекта вектор с тремя элементами, для начала заполняем единицу\n",
        "y_vec0 = np.zeros((n,3))\n",
        "y_vec1 = np.zeros((n,3))\n",
        "\n",
        "# в каждом ряду проставляем 1 в нужном классе\n",
        "for i in range(n):\n",
        "    # если метка класса 0, значит ставим один в нулевую ячйку\n",
        "    if y[i] == 0:\n",
        "        y_vec0[i, 0] = 1\n",
        "    # если метка класса 1, значит ставим один в первую ячйку\n",
        "    if y[i] == 1:\n",
        "        y_vec0[i, 1] = 1\n",
        "    # если метка класса 2, значит ставим один в вторую ячйку\n",
        "    if y[i] == 2:\n",
        "        y_vec0[i, 2] = 1\n",
        "\n",
        "# теперь y_vec0 содержит метки классов в виде векторов\n",
        "\n",
        "# попробуйте:\n",
        "# заполнить y_vec1 с помощь цикла, но без if'ов\n",
        "\n",
        "# при совпадении должны быть все нули\n",
        "# print(y_vec0 - y_vec1)\n",
        "        \n",
        "# logloss\n",
        "L = None"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Скалярные произведения:  (20, 3)\n",
            "Экспоненты от скалярных произведений:  (20, 3)\n",
            "Знаменатели:  (20,)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}