{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled31.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9cybbjDQqci",
        "colab_type": "text"
      },
      "source": [
        "# Подготовка входных данных\n",
        "В спорте сложно подготовить универсального спортсмена даже в одной области: большинство бегунов специализируется на конкретной дистанции. Большинство пловцов показывают хорошие результаты только в одном стиле плавания.\n",
        "Похожая ситуация и в других областях: чаще всего человек оказывается лучшим в чем-то одном (наука, исскуство).\n",
        "\n",
        "Эту аналогию можно распространить и на машинное обучение: сложно построить универсальную модель, которая будет работать со всевозможными данными, пусть даже и из одной области.\n",
        "\n",
        "Обойти эту проблему можно несколькими способами. Можно разделить исходную задачу на более мелкие (чтобы входные данные были более однородны) и обучить моедели для каждой задачи отдельно. Однако это сильно усложнит и удлинит процесс разработки.\n",
        "\n",
        "Другой подход - обучать одну модель, но сделать данные более однородными, привести их к \"стандартному\" виду. Такой подход называется нормализацией входных данных.\n",
        "\n",
        "Что можно считать стандартными значениями для переменной вещественной переменной?\n",
        "\n",
        "1. Интервал $(-\\infty, \\infty)$ - слишком большой разброс, неудобно\n",
        "2. Интервал $[0, \\infty)$ - чуть лучше, но все равно проблемно\n",
        "3. Интервал $[0, 1]$ -   переодически используется. Недостаток: многие соотношения используют \"знак\" выражения, при таком выборе нет симметрии между отрицательными и положительными значениями\n",
        "4. Интервал $[-1,1]$ - используется. Недостаток: представим сеюе набор данных, в котором есть значение -1000, затем значения из промежутка $[-1,1]$ и последние - 1000. Если такой набор сжать в промежуток $[-1,1]$, то основные данные будут лежать в очень маленькой его части.\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5ATRFDTfXST",
        "colab_type": "text"
      },
      "source": [
        "Основной подход:\n",
        "\n",
        "1. Вычислим среднее арифметическое значение данных. Сохраним его в переменную mean. Вычтем среднее из всех значений, тогда среднее нового набора будет 0. То есть данные будут лежать симметрично относительно 0.\n",
        "2. Посчитаем насколько начальные значения отличаются от среднего: вычтем из начальных данных среднее и каждое выражение возведем в квадрат:\n",
        "$$\\Delta x_i^2= (x_i-mean)^2$$\n",
        "3. Найдем среднее таких квадратичных отклонений и извлечем из него корень:\n",
        "$$\\sigma = \\sqrt{\\frac{\\Sigma_i \\Delta x_i^2}{N}}$$\n",
        "\n",
        "    Тогда если начальные данные были распределены нормально, то в промежуток $[-\\sigma, \\sigma]$ попадет ~68% всех значений.\n",
        "    ![Распределение данных при нормальном распределении](https://raw.githubusercontent.com/mlforschool/lessons/master/6_Norm_and_Regular/Images/Standard_deviation_diagram.svg.png)\n",
        "    (Изображение взято со страницы https://en.wikipedia.org/wiki/Standard_deviation#/media/File:Standard_deviation_diagram.svg)\n",
        "\n",
        "    4. Теперь мы можем поделить входные данные на $\\sigma$ и тогда ~68%  в промежутке [-1,1].\n",
        "    5. На нормаллизованнных данных модель будет обучаться быстрее и давать более точные прогнозы.\n",
        "    \n",
        "    \n",
        "    Такой алгоритм нужно применить к каждой компоненте входных данных: если каждый объект рписывается 3 значениями, то нужно посчитать три средних, три $\\sigma$ и выполнить 3 нормализации\n",
        "    \n",
        "    \n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cayrPwnZhlLI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def generate_data(size = 10):\n",
        "    # случайные точки\n",
        "    # числа из диапазона [0,1]\n",
        "    X = np.random.rand(size, 2) \n",
        "    \n",
        "    X[:,0] = X[:,0] *0.5 + 5\n",
        "    X[:,1] = X[:,1] *120 - 13 \n",
        "    print(X)\n",
        "    \n",
        "    # задаем функцию для ответов\n",
        "    mask = 0.12 * X[:, 1] **2 + X[:, 0] * 10 - X[:, 1] * 7\n",
        "    \n",
        "    # добавляем шум\n",
        "    mask = mask + np.random.rand(size) * 0.2\n",
        "    \n",
        "    \n",
        "    # классы\n",
        "    y = np.zeros(size, dtype=int)\n",
        "    y[mask >= 0] = 1\n",
        "    y[mask < 0] = 0\n",
        "    \n",
        "    \n",
        "    \n",
        "    return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAWWgcUlkCjM",
        "colab_type": "text"
      },
      "source": [
        "## Задание\n",
        "\n",
        "Сгенерируйте данные 100 точек и приведите их стандартному виду с помощью описанного выше алгоритма"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ov4w5wPXjoUG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# начальные данный\n",
        "X, y = None, None\n",
        "\n",
        "# считаем средние\n",
        "# не забудьте, что у команды mean есть параметр axis, который указывает ось по кторой считается среднее\n",
        "mean = None\n",
        "\n",
        "# вычитаем среднее\n",
        "X1 = None\n",
        "\n",
        "# возводим все разности в квадрат\n",
        "dX = None\n",
        "\n",
        "# находим среднее от разностей\n",
        "# не забудьте, что у команды mean есть параметр axis, который указывает ось по кторой считается среднее\n",
        "var = None\n",
        "\n",
        "\n",
        "# извлекаем корень:\n",
        "sigmas = None\n",
        "\n",
        "# делим значения на сигмы и получаем нормализованные данные\n",
        "res = None\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Wimkhshjqc5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# существуют уже готовые пакеты для нормализации данных\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "res2 = sc.fit_transform(X)\n",
        "\n",
        "# сравните свой res и res2, их разность должна получится 0\n",
        "if res and res2:\n",
        "    print(res - res2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIaRSDWSqdJ9",
        "colab_type": "text"
      },
      "source": [
        "Используем данные для обучения логистической регрессии"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poJ5p3b5qc3i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RX3p5pKLxXss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# не нормализованные данные\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "lr = LogisticRegression().fit(X_train, y_train)\n",
        "\n",
        "print(lr.score(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q92sN7dwqFVy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# нормализованные данные\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(res, y, test_size=0.33, random_state=42)\n",
        "lr2 = LogisticRegression().fit(X_train2, y_train2)\n",
        "\n",
        "lr2.score(X_test2, y_test2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uR5SV6dxkfV",
        "colab_type": "text"
      },
      "source": [
        "Различие минимально, но оно есть.\n",
        "\n",
        "Чем более сложные и нелинейные модели мы будем использовать, тем чуствительнее они будут к нормализации данных\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5qrvdQqyCVY",
        "colab_type": "text"
      },
      "source": [
        "# Задание 2\n",
        "Выполните обратное преобразование данных.\n",
        "Используя mean и sigma получите из нормализованных  данных исходные"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFp7_zbyxzNE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# нормализованные данные\n",
        "res, mean, sigmas\n",
        "\n",
        "# ваш код\n",
        "\n",
        "\n",
        "X_new = None\n",
        "\n",
        "\n",
        "# сравнение, максимальный модуль разности\n",
        "# должен быть 0\n",
        "if X and X_new:\n",
        "    print(np.max(np.abs(X - X_new))\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}